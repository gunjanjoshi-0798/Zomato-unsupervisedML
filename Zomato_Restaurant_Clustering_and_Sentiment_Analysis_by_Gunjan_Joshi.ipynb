{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "MSa1f5Uengrz",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gunjanjoshi-0798/Zomato-unsupervisedML/blob/main/Zomato_Restaurant_Clustering_and_Sentiment_Analysis_by_Gunjan_Joshi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -  Zomato Restaurant Clustering and Sentiment Analysis.\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Name**    - Gunjan Joshi\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zomato is an Indian restaurant aggregator and food delivery start-up founded by Deepinder Goyal and Pankaj Chaddah in 2008. Zomato provides information, menus and user-reviews of restaurants, and also has food delivery options from partner restaurants in select cities.\n",
        "\n",
        "India is quite famous for its diverse multi cuisine available in a large number of restaurants and hotel resorts, which is reminiscent of unity in diversity. Restaurant business in India is always evolving. More Indians are warming up to the idea of eating restaurant food whether by dining outside or getting food delivered. The growing number of restaurants in every state of India has been a motivation to inspect the data to get some insights, interesting facts and figures about the Indian food industry in each city. So, this project focuses on analysing the Zomato restaurant data for each city in India.\n",
        "\n",
        "There are two separate files, while the columns are self explanatory. Below is a brief description:\n",
        "\n",
        "Restaurant names and Metadata - This could help in clustering the restaurants into segments. Also the data has valuable information around cuisine and costing which can be used in cost vs. benefit analysis Restaurant reviews - Data could be used for sentiment analysis. Also the metadata of reviewers can be used for identifying the critics in the industry.\n",
        "\n",
        "Steps that are performed:\n",
        "\n",
        "Importing libraries\n",
        "\n",
        "Loading the dataset\n",
        "\n",
        "Shape of dataset\n",
        "\n",
        "Dataset information\n",
        "\n",
        "Handling the duplicate values\n",
        "\n",
        "Handling missing values\n",
        "\n",
        "Understanding the columns\n",
        "\n",
        "Variable description\n",
        "\n",
        "Data wrangling\n",
        "\n",
        "Data visualization\n",
        "\n",
        "Story telling and experimenting with charts.\n",
        "\n",
        "Text preprocessing\n",
        "\n",
        "Latent Direchlet Allocation\n",
        "\n",
        "Sentiment analysis\n",
        "\n",
        "Challenges faced\n",
        "\n",
        "Conclusion"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zomato Restaurant Clustering and Sentiment Analysis by Gunjan Joshi.ipynb"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Project focuses on Customers and Company, you have to analyze the sentiments of the reviews given by the customer in the data and made some useful conclusion in the form of Visualizations. Also, cluster the zomato restaurants into different segments. The data is vizualized as it becomes easy to analyse data at instant. The Analysis also solve some of the business cases that can directly help the customers finding the Best restaurant in their locality and for the company to grow up and work on the fields they are currently lagging in.\n",
        "\n",
        "This could help in clustering the restaurants into segments. Also the data has valuable information around cuisine and costing which can be used in cost vs. benefit analysis\n",
        "\n",
        "Data could be used for sentiment analysis. Also the metadata of reviewers can be used for identifying the critics in the industry."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
        "from nltk.stem import PorterStemmer, LancasterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from textblob import TextBlob\n",
        "from IPython.display import Image\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "from gensim.utils import simple_preprocess\n",
        "import gensim\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta_df_main=pd.read_csv('/content/drive/MyDrive/Zomato Restaurant names and Metadata.csv')\n",
        "review_df=pd.read_csv('/content/drive/MyDrive/Zomato Restaurant reviews.csv')"
      ],
      "metadata": {
        "id": "_Q5SAUN0XyDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "meta_df_main"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta_df_main.head()"
      ],
      "metadata": {
        "id": "qEjmcy01YYWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta_df_main.tail()"
      ],
      "metadata": {
        "id": "-Uj-UNHFYbEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_df"
      ],
      "metadata": {
        "id": "fPFLlyejYhRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Meta Dataset Rows & Columns count\n",
        "print(f\"Number of rows: {len(meta_df_main.axes[0])}\")\n",
        "print(f\"Number of columns: {len(meta_df_main.axes[1])}\")"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Review Dataset Rows & Columns count\n",
        "print(f\"Number of rows: {len(review_df.axes[0])}\")\n",
        "print(f\"Number of columns: {len(review_df.axes[1])}\")"
      ],
      "metadata": {
        "id": "67L9YIB5Ysc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "meta_df_main.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_df.info()"
      ],
      "metadata": {
        "id": "Qn4rCcSSZCa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "(meta_df_main.duplicated()).value_counts()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(review_df.duplicated()).value_counts()"
      ],
      "metadata": {
        "id": "ZtGHHZHsZR7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "meta_df_main.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "sns.heatmap(meta_df_main.isnull().transpose(),cmap='coolwarm',annot=False,yticklabels=False)\n",
        "plt.title(\" Visualising Missing Values\");\n"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our data has missing values in collection column. Since the column contains sentiments hence no need to impute the null values.\n",
        "\n",
        "1. There are 105 total observation with 6 different features.\n",
        "2. Feature like collection and timing has null values.\n",
        "3. There is no duplicate values i.e., 105 unique data.\n",
        "4. Feature cost represent amount but has object data type because these values are separated by comma ','.\n",
        "5. Timing represent operational hour but as it is represented in the form of text has object data type."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "meta_df_main.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_df.columns"
      ],
      "metadata": {
        "id": "55rBC41Xate3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "meta_df_main.describe().T"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zomato Restaurant names and Metadata**\n",
        "\n",
        "*   Name : Name of Restaurants\n",
        "*   Links : URL Links of Restaurants\n",
        "*   Cost : Per person estimated Cost of dining\n",
        "*   Collection : Tagging of Restaurants w.r.t. Zomato categories\n",
        "*   Cuisines : Cuisines served by Restaurants\n",
        "*   Timings : Restaurant Timings\n",
        "\n",
        "**Zomato Restaurant reviews**\n",
        "*   Restaurant : Name of the Restaurant\n",
        "*  Reviewer : Name of the Reviewer\n",
        "\n",
        "* Review : Review Text\n",
        "\n",
        "* Rating : Rating Provided by Reviewer\n",
        "\n",
        "* MetaData : Reviewer Metadata - No. of Reviews and followers\n",
        "\n",
        "* Time: Date and Time of Review\n",
        "\n",
        "* Pictures : No. of pictures posted with review"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "pd.Series({col:meta_df_main[col].nunique() for col in meta_df_main})"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "meta_df = meta_df_main.copy()"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the 'Cost' column, deleting the comma and changing the data type into 'int64'.\n",
        "meta_df['Cost'] =  meta_df['Cost'].str.replace(\",\",\"\").astype('int64')"
      ],
      "metadata": {
        "id": "r9SHjpJ7cdHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta_df.info()"
      ],
      "metadata": {
        "id": "GAEEEYVucmBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "first I made the copy of the original dataframe so that any changes to dataframe doesn't affect the original dataframe. And then I changed the datatype of cost from object to int type."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "# Affordable price restaurants.\n",
        "\n",
        "plt.figure(figsize=(15,6))\n",
        "\n",
        "# Performing groupby To get values accourding to Names and sort it for visualisation.\n",
        "top_10_affor_rest=meta_df[['Name','Cost']].groupby('Name',as_index=False).sum().sort_values(by='Cost',ascending=False).tail(10)\n",
        "\n",
        "# Lables for X and Y axis\n",
        "x = top_10_affor_rest['Cost']\n",
        "y = top_10_affor_rest['Name']\n",
        "\n",
        "# Assigning the arguments for chart\n",
        "plt.title(\"Top 10 Affordable Restaurant\",fontsize=20, weight='bold',color=sns.cubehelix_palette(8, start=.5, rot=-.75)[-3])\n",
        "plt.ylabel(\"Name\",weight='bold',fontsize=15)\n",
        "plt.xlabel(\"Cost\",weight='bold',fontsize=15)\n",
        "plt.xticks(rotation=90)\n",
        "sns.barplot(x=x, y=y,palette='rocket')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The plot shows the top 10 affordable restaurants based on their total cost. The y-axis represents the restaurant names, while the x-axis shows the total cost. The affordable restaurants are sorted in ascending order of their cost."
      ],
      "metadata": {
        "id": "iVPex6IyJywa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# Visualisation the value counts of collection.\n",
        "meta_df['Collections'].value_counts()[0:10].sort_values().plot(figsize=(10,8),kind='barh')"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The resulting bar chart shows the top 10 most frequent values in the Collections column on the y-axis and their corresponding counts on the x-axis. The horizontal orientation of the bars makes it easy to compare the counts of the different collections. The longer the bar, the higher the count."
      ],
      "metadata": {
        "id": "9hl7DtFyKFMo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "\n",
        "top10_res_by_cost = meta_df[['Name','Cost']].groupby('Name',as_index=False).sum().sort_values(by='Cost',ascending=False).head(10)"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating word cloud for expensive restaurants.\n",
        "plt.figure(figsize=(15,8))\n",
        "text = \" \".join(name for name in meta_df.sort_values('Cost',ascending=False).Name[:30])\n",
        "\n",
        "# Creating word_cloud with text as argument in .generate() method.\n",
        "word_cloud = WordCloud(width = 1400, height = 1400,collocations = False, background_color = 'black').generate(text)\n",
        "\n",
        "# Display the generated Word Cloud.\n",
        "plt.imshow(word_cloud, interpolation='bilinear')\n",
        "\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "wC6NQ1JddizA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text preprocessing for the meta dataset.**"
      ],
      "metadata": {
        "id": "44jsvgCXdxT8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Order to plot the cuisines from the data we have to count the frequency of the words from the document.(Frequency of cuisine). For that We have to perform the opration like removing stop words, Convert all the text into lower case, removing punctuations, removing repeated charactors, removing Numbers and emojies and finally count vectorizer."
      ],
      "metadata": {
        "id": "o4vovgcbeH2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading and importing the dependancies for text cleaning.\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "YzqtnUb7eN5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting the stopwords from nltk library for English corpus.\n",
        "sw = stopwords.words('english')"
      ],
      "metadata": {
        "id": "cmk66UqCeR0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a function for removing stopwords.\n",
        "def stopwords(text):\n",
        "    '''a function for removing the stopword'''\n",
        "\n",
        "    # removing the stop words and lowercasing the selected words\n",
        "    text = [word.lower() for word in str(text).split() if word.lower() not in sw]\n",
        "\n",
        "    # joining the list of words with space separator\n",
        "    return \" \".join(text)"
      ],
      "metadata": {
        "id": "9T7ruDfreU9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing stopwords from Cuisines.\n",
        "meta_df['Cuisines'] = meta_df['Cuisines'].apply(lambda text: stopwords(text))\n",
        "meta_df['Cuisines'].head()"
      ],
      "metadata": {
        "id": "-YrzPjryeYN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the function for removing punctuation.\n",
        "def remove_punctuation(text):\n",
        "    '''a function for removing punctuation'''\n",
        "    import string\n",
        "\n",
        "    # replacing the punctuations with no space,\n",
        "    # which in effect deletes the punctuation marks\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "\n",
        "    # return the text stripped of punctuation marks\n",
        "    return text.translate(translator)"
      ],
      "metadata": {
        "id": "kaKUQTsyeb6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing punctuation from Cuisines.\n",
        "meta_df['Cuisines'] = meta_df['Cuisines'].apply(lambda x: remove_punctuation(x))\n",
        "meta_df['Cuisines'].head()"
      ],
      "metadata": {
        "id": "3lY-1rByee_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning and removing Numbers.\n",
        "import re\n",
        "\n",
        "# Writing a function to remove repeating characters.\n",
        "def cleaning_repeating_char(text):\n",
        "    return re.sub(r'(.)1+', r'1', text)"
      ],
      "metadata": {
        "id": "7bU65ufIei0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing repeating characters from Cuisines.\n",
        "meta_df['Cuisines'] = meta_df['Cuisines'].apply(lambda x: cleaning_repeating_char(x))\n",
        "meta_df['Cuisines'].head()"
      ],
      "metadata": {
        "id": "QP7KqooDemqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing the Numbers from the data.\n",
        "def cleaning_numbers(data):\n",
        "    return re.sub('[0-9]+', '', data)"
      ],
      "metadata": {
        "id": "OV4ZfAtVevBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing the cleaning.\n",
        "meta_df['Cuisines'] = meta_df['Cuisines'].apply(lambda x: cleaning_numbers(x))\n",
        "meta_df['Cuisines'].head()"
      ],
      "metadata": {
        "id": "X4-Mwshaewg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 20 Two word Frequencies of Cuisines.\n",
        "from collections import Counter\n",
        "text = ' '.join(meta_df['Cuisines'])\n",
        "\n",
        "# separating each word from the sentences\n",
        "words = text.split()\n",
        "\n",
        "# Extracting the first word from the number for cuisines in the sentence.\n",
        "two_words = {' '.join(words):n for words,n in Counter(zip(words, words[1:])).items() if not  words[0][-1]==(',')}"
      ],
      "metadata": {
        "id": "8L4zwSage7Xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting the most frequent cuisine present in the collection.\n",
        "# Counting a frequency for cuisines.\n",
        "two_words_dfc = pd.DataFrame(two_words.items(), columns=['Cuisine', 'Frequency'])\n",
        "\n",
        "# Sorting the most frequent cuisine at the top and order by descending\n",
        "two_words_dfc = two_words_dfc.sort_values(by = \"Frequency\", ascending = False)\n",
        "\n",
        "# selecting first top 20 frequent cuisine.\n",
        "two_words_20c = two_words_dfc[:20]\n",
        "two_words_20c"
      ],
      "metadata": {
        "id": "63bLJT9Me_oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "\n",
        "# Visualizing the frequency of the Cuisines.\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize = (18, 8))\n",
        "sns.barplot(y = \"Cuisine\", x = \"Frequency\", data = two_words_20c, palette = \"magma\")\n",
        "plt.title(\"Top 20 Two-word Frequencies of Cuisines\", size = 20)\n",
        "plt.xticks(size = 15)\n",
        "plt.yticks(size = 15)\n",
        "plt.xlabel(\"Cuisine\", size = 20)\n",
        "plt.ylabel(None)\n",
        "plt.savefig(\"Top_20_Two-word_Frequencies_of_Cuisines.png\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The DataFrame contains two columns: \"Cuisine\" and \"Frequency.\" The \"Cuisine Words\" column lists the most frequent two-word cuisine terms, while the \"Frequency\" column shows the number of times each two-word cuisine term appears in the dataset.This information can be helpful in understanding the most common cuisine types in the dataset. It can also be used to identify trends and patterns in the types of cuisines that are popular or in demand among the customers."
      ],
      "metadata": {
        "id": "KEOU3-vdKjFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# proportion or percentage of occurrences for each unique value in the Rating column.\n",
        "review_df['Rating'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "7QEpGC4jgLPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing like value and taking the mean in the rating column.\n",
        "review_df.loc[review_df['Rating'] == 'Like'] = np.nan\n",
        "\n",
        " # Chenging the data type of rating column\n",
        "review_df['Rating']= review_df['Rating'].astype('float64')\n",
        "\n",
        "print(review_df['Rating'].mean())"
      ],
      "metadata": {
        "id": "HG7APtY3gYen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling mean in place of null value\n",
        "review_df['Rating'].fillna(3.6, inplace=True)"
      ],
      "metadata": {
        "id": "W66wRSaDghNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing the data type of review column.\n",
        "review_df['Review'] = review_df['Review'].astype(str)\n",
        "\n",
        "# Creating a review_length column to check the frequency of each rating.\n",
        "review_df['Review_length'] = review_df['Review'].apply(len)"
      ],
      "metadata": {
        "id": "bB2pjMe4gnhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_df['Rating'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "SZzxjwBBgwDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Ratings distribution 38% reviews are 5 rated,23% are 4 rated stating that people do rate good food high."
      ],
      "metadata": {
        "id": "etcUXXT5U7qa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split metadata column into 2 columns i.e. Reviews and followers\n",
        "review_df['Reviews'],review_df['Followers']= review_df['Metadata'].str.split(',').str\n",
        "review_df['Reviews'] = pd.to_numeric(review_df['Reviews'].str.split(' ').str[0])"
      ],
      "metadata": {
        "id": "aqFPmrZ7Un-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_df['Followers']= pd.to_numeric(review_df['Followers'].str.split(' ').str[1])"
      ],
      "metadata": {
        "id": "xFY9TcYCUuo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_df.head()"
      ],
      "metadata": {
        "id": "Q4g5aSZlU0ZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting Time column into Time, Year, Month, Hour\n",
        "review_df['Time']=pd.to_datetime(review_df['Time'])\n",
        "review_df['Year'] = pd.DatetimeIndex(review_df['Time']).year\n",
        "review_df['Month'] = pd.DatetimeIndex(review_df['Time']).month\n",
        "review_df['Hour'] = pd.DatetimeIndex(review_df['Time']).hour\n",
        "review_df = review_df.drop(['Metadata'], axis =1)"
      ],
      "metadata": {
        "id": "BqAlOpeTVGYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_df.head()"
      ],
      "metadata": {
        "id": "SGMpvQ16VLMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_df.isnull().sum()"
      ],
      "metadata": {
        "id": "badGTENDVPtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing followers and reviews null values into 0\n",
        "review_df['Followers'].fillna(0,inplace=True)\n",
        "review_df['Reviews'].fillna(0,inplace=True)"
      ],
      "metadata": {
        "id": "uGUrv2vtVUTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can drop the remaining missing data\n",
        "review_df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "cCJ6Fu5fVWYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_df.reset_index(inplace = True)"
      ],
      "metadata": {
        "id": "AoxdhOMHVdrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_df.isnull().sum()"
      ],
      "metadata": {
        "id": "8eaKJngJVhXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "\n",
        "# Countplot of Ratings\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.countplot(x= review_df['Rating'],palette=\"plasma\")\n",
        "plt.title(\"Count of Ratings\",fontsize=20, weight='bold',color=sns.cubehelix_palette(8, start=.5, rot=-.75)[-3])\n",
        "plt.ylabel(\"Count\",weight='bold',fontsize=15)\n",
        "plt.xlabel(\"Ratings\",weight='bold',fontsize=15)"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bar plot confirms that maximum rating given is 5."
      ],
      "metadata": {
        "id": "_j4IAy6qhK2z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.histplot(review_df.Time)"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.countplot(x= review_df.Month)"
      ],
      "metadata": {
        "id": "iTdPrscwWad8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing dependancies and removing stopwords.\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Creating argument for stop words.\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "print(stop_words)"
      ],
      "metadata": {
        "id": "DdAQz2DDh1Oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stopwords(text):\n",
        "    '''a function for removing the stopword'''\n",
        "    # removing the stop words and lowercasing the selected words\n",
        "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
        "    # joining the list of words with space separator\n",
        "    return \" \".join(text)"
      ],
      "metadata": {
        "id": "6nMmrwQwL9bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rest_word=['order','restaurant','taste','ordered','good','food','table','place','one','also']\n",
        "rest_word"
      ],
      "metadata": {
        "id": "PGs_5-WgLjBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "\n",
        "# We will extrapolate the 15 profiles that have made more reviews.\n",
        "\n",
        "# Groupby on the basis of rivewer gives the fequency of the reviews\n",
        "reviewer_list = review_df.groupby('Reviewer').apply(lambda x: x['Reviewer'].count()).reset_index(name='Review_Count')\n",
        "\n",
        " # Sorting the frequency of reviews decending\n",
        "reviewer_list = reviewer_list.sort_values(by = 'Review_Count',ascending=False)\n",
        "\n",
        "# Selecting the top 15 reviewrs\n",
        "top_reviewers = reviewer_list[:15]"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the top 15 reviewers.\n",
        "plt.figure(figsize=(13,5))\n",
        "plt.bar(top_reviewers['Reviewer'], top_reviewers['Review_Count'], color = sns.color_palette(\"hls\", 8))\n",
        "plt.xticks(rotation=75)\n",
        "plt.title('Top 15 reviews',size=28)\n",
        "plt.xlabel(\"Reviewer's Name\",size=15)\n",
        "plt.ylabel('No of reviews',size=15)"
      ],
      "metadata": {
        "id": "TP5o0S04iFnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "# Calculate the average of their ratings review.\n",
        "review_ratings=review_df.groupby('Reviewer').apply(lambda x:np.average(x['Rating'])).reset_index(name='Average_Ratings')\n",
        "review_ratings=pd.merge(top_reviewers,review_ratings,how='inner',left_on='Reviewer',right_on='Reviewer')\n",
        "top_reviewers_ratings=review_ratings[:15].sort_values(by = 'Average_Ratings',ascending=False)"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Average rating of top reviewers.\n",
        "plt.figure(figsize=(15,6))\n",
        "x = top_reviewers_ratings['Average_Ratings']\n",
        "y = top_reviewers_ratings['Reviewer']\n",
        "plt.title(\"Top 15 reviewers with average rating of review\",fontsize=20, weight='bold',color=sns.cubehelix_palette(8, start=.5, rot=90)[-5])\n",
        "plt.ylabel(\"Name\",weight='bold',fontsize=15)\n",
        "plt.xlabel(\"Average Ratings\",weight='bold',fontsize=15)\n",
        "plt.xticks(rotation=90)\n",
        "sns.barplot(x=x, y=y,palette='plasma')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ig88Mg-9iSFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output of top 15 reviewers based on the number of reviews they have made in a given dataset. Analyzing the reviews made by these top reviewers can help in improving customer satisfaction and loyalty, ultimately leading to increased revenue and growth."
      ],
      "metadata": {
        "id": "hlopuam8jLP8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "review= review_df.Review\n",
        "review"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_df['Review'] = review_df['Review'].apply(remove_punctuation)"
      ],
      "metadata": {
        "id": "c_6uYy7MasV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_df['Review'] = review_df['Review'].apply(stopwords)"
      ],
      "metadata": {
        "id": "7fyIupmZa1rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review=review_df.Review\n",
        "review"
      ],
      "metadata": {
        "id": "fqt6gcPgbRo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "qKvmOkTmbVsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatization_(text):\n",
        "  for index,x in enumerate(text):\n",
        "    doc = nlp(x)\n",
        "    l=list()\n",
        "    for word in doc:\n",
        "        l.append(word.lemma_)\n",
        "    text[index]=' '.join(l)\n",
        "  return text"
      ],
      "metadata": {
        "id": "PLXpoqnyba9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove_all_extra_spaces\n",
        "def remove_spaces (text):\n",
        "  '''removes all extra space from the text\n",
        "  '''\n",
        "  for index,x in enumerate(text):\n",
        "    text[index]=\" \".join(x.split())\n",
        "  return text"
      ],
      "metadata": {
        "id": "y5xiOmPdbyP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review=remove_spaces(review)"
      ],
      "metadata": {
        "id": "GKGNYix0b115"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove non letters\n",
        "import re\n",
        "regex = re.compile('[^a-zA-Z]')\n",
        "def remove_non_leters(text):\n",
        "  '''used to remove all non leters form the list\n",
        "  '''\n",
        "  text=[regex.sub(' ', x) for x in text]\n",
        "  return text"
      ],
      "metadata": {
        "id": "b4vTSxc9b5Au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review=remove_non_leters(review)"
      ],
      "metadata": {
        "id": "Q6qVHVrab77A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the reviews in a feature of df\n",
        "review_df['Review']=review\n",
        "review_df.head()"
      ],
      "metadata": {
        "id": "lZ3yY2sVb_lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to removing words greater than 45 and less than 2\n",
        "def len_less_than2(review):\n",
        "  review=\" \".join([i for i in review.split() if len(i)>2])\n",
        "  review=\" \".join([i for i in review.split() if len(i)<=45])\n",
        "  return review"
      ],
      "metadata": {
        "id": "bgDIoB8PcFNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing words greater than 45 and less than 2\n",
        "review_df['Review']=review_df['Review'].apply(lambda x:len_less_than2(x))"
      ],
      "metadata": {
        "id": "ZlG1NFKjcIWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Word cloud for positive reviews.\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "review_df['Review']=review_df['Review'].astype(str)\n",
        "\n",
        "ps = PorterStemmer()\n",
        "review_df['Review']=review_df['Review'].map(lambda x: ps.stem(x))\n",
        "long_string = ','.join(list(review_df['Review'].values))\n",
        "long_string\n",
        "wordcloud = WordCloud(background_color=\"white\", max_words=100, contour_width=3, contour_color='steelblue')\n",
        "wordcloud.generate(long_string)\n",
        "wordcloud.to_image()"
      ],
      "metadata": {
        "id": "roOYaewFjibk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "top10_rated = review_df.groupby(\"Restaurant\")[\"Rating\"].max().nlargest(10)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=top10_rated.values, y=top10_rated.index, palette='viridis')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Restaurant')\n",
        "plt.title('Top 10 Restaurants based on Maximum Ratings')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By employing the barplot visualization, I have successfully identified and displayed the top-rated restaurants, offering a clear and concise view of the dining establishments that have received the highest accolades and positive feedback from customers. Among them, 10 Downing Street, 13 Dhaba, and Barbeque Nation emerge as the most highly rated choices."
      ],
      "metadata": {
        "id": "zYVYyHSWTIh-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "# Creating two datasets for positive and negative reviews.\n",
        "\n",
        "review_df['Rating']= pd.to_numeric(review_df['Rating'],errors='coerce')   # The to_numeric() function in pandas is used to convert a pandas object to a numeric type.\n",
        "pos_rev = review_df[review_df.Rating>= 3]\n",
        "neg_rev = review_df[review_df.Rating< 3]"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Negative reviews wordcloud.\n",
        "\n",
        "long_string = ','.join(list(neg_rev['Review'].values))\n",
        "long_string\n",
        "wordcloud = WordCloud(background_color=\"white\", max_words=100, contour_width=3, contour_color='steelblue')\n",
        "wordcloud.generate(long_string)\n",
        "wordcloud.to_image()"
      ],
      "metadata": {
        "id": "Czrmk_QHc6TF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a corpus of words from the negative reviews in the neg_rev DataFrame."
      ],
      "metadata": {
        "id": "t7_jvrryc-YS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating word embeddings and t-SNE plot. (for positive and negative reviews).\n",
        "\n",
        "from gensim.models import word2vec\n",
        "pos_rev = review_df[review_df.Rating>= 3]\n",
        "neg_rev = review_df[review_df.Rating< 3]"
      ],
      "metadata": {
        "id": "2BHXomrvdMxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataframe where the Rating column is greater than or equal to 3. This selects all the positive reviews where as the Rating column is less than 3. This selects all the negative reviews, assuming that the Rating column is a scale from 1 to 5 with 5 being the highest rating."
      ],
      "metadata": {
        "id": "AV3f-42mdQoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot for negative reviews.\n",
        "def build_corpus(data):\n",
        "    \"Creates a list of lists containing words from each sentence\"\n",
        "    corpus = []\n",
        "    for col in ['Review']:\n",
        "        for sentence in data[col].iteritems():\n",
        "            word_list = sentence[1].split(\" \")\n",
        "            corpus.append(word_list)\n",
        "\n",
        "    return corpus\n",
        "\n",
        "# Display the first two elements of the corpus list\n",
        "corpus = build_corpus(neg_rev)\n",
        "corpus[0:2]"
      ],
      "metadata": {
        "id": "yUhtjcGtdEk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a corpus of words from the positive reviews in the neg_rev DataFrame.**"
      ],
      "metadata": {
        "id": "RMPkgg4udXS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot for postive reviews\n",
        "def build_corpus(data):\n",
        "    \"Creates a list of lists containing words from each sentence\"\n",
        "    corpus = []\n",
        "    for col in ['Review']:\n",
        "        for sentence in data[col].iteritems():\n",
        "            word_list = sentence[1].split(\" \")\n",
        "            corpus.append(word_list)\n",
        "\n",
        "    return corpus\n",
        "\n",
        "# Display the first two elements of the corpus list\n",
        "corpus = build_corpus(pos_rev)\n",
        "corpus[0:2]"
      ],
      "metadata": {
        "id": "uL_LU_-QdeAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for the implimented code\n",
        "review_df['Review']"
      ],
      "metadata": {
        "id": "VYWnpIGLdh14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***LDA***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "from gensim.utils import simple_preprocess"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume that documents is a list of strings representing text documents\n",
        "\n",
        "# Tokenize the documents\n",
        "tokenized_docs = [simple_preprocess(doc) for doc in review_df['Review']]\n",
        "\n",
        "# Create a dictionary from the tokenized documents\n",
        "dictionary = corpora.Dictionary(tokenized_docs)\n",
        "\n",
        "# Convert the tokenized documents to a bag-of-words corpus\n",
        "bow_corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs]\n",
        "\n",
        "# Train an LDA model on the bag-of-words corpus\n",
        "num_topics = 10  # The number of topics to extract\n",
        "lda_model = LdaModel(bow_corpus, num_topics=num_topics, id2word=dictionary, passes=10)\n",
        "\n",
        "# Print the topics and their top 10 terms\n",
        "for topic in lda_model.show_topics(num_topics=num_topics, num_words=10, formatted=False):\n",
        "    print('Topic {}: {}'.format(topic[0], ', '.join([term[0] for term in topic[1]])))"
      ],
      "metadata": {
        "id": "Y63TcJBsgCN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyLDAvis"
      ],
      "metadata": {
        "id": "_ZWWJ3V-gG7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import pyLDAvis\n",
        "#import pyLDAvis.sklearn\n",
        "pyLDAvis.enable_notebook()"
      ],
      "metadata": {
        "id": "04u5qfl5gKMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_raw = review_df['Review'].tolist()"
      ],
      "metadata": {
        "id": "qzr9MrK3Qrsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transform text to vector form using the vectorizer object\n",
        "tf_vectorizer = CountVectorizer(strip_accents = 'unicode',\n",
        "                                stop_words = 'english',\n",
        "                                lowercase = True,\n",
        "                                token_pattern = r'\\b[a-zA-Z]{10,}\\b', # num chars > 3 to avoid some meaningless words\n",
        "                                max_df = 0.9,                        # discard words that appear in > 90% of the reviews\n",
        "                                min_df = 10)\n",
        "\n"
      ],
      "metadata": {
        "id": "LXdU41K5Q1Am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#apply transformation\n",
        "tfidf_vectorizer = TfidfVectorizer(**tf_vectorizer.get_params())"
      ],
      "metadata": {
        "id": "djExKKGuQ6qR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtm_tfidf = tfidf_vectorizer.fit_transform(docs_raw)"
      ],
      "metadata": {
        "id": "qF0U41kBRscE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The shape of the tfidf is {}, meaning that there are {} {} and {} tokens made through the filtering process.\".\\\n",
        "              format(dtm_tfidf.shape,dtm_tfidf.shape[0], review_df['Review'], dtm_tfidf.shape[1]))"
      ],
      "metadata": {
        "id": "P84QkfpOR16Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Search Param\n",
        "search_params = {'n_components': [5, 10, 15, 20, 25, 30], 'learning_decay': [.5, .7, .9]}"
      ],
      "metadata": {
        "id": "BECKbk8eR-Rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Init the Model\n",
        "lda = LatentDirichletAllocation()"
      ],
      "metadata": {
        "id": "tAl_p9gYSEF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GridSearchCV(lda, param_grid=search_params)"
      ],
      "metadata": {
        "id": "90P6meoLSH0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(dtm_tfidf)"
      ],
      "metadata": {
        "id": "tepKbkOGSLw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_lda_model = model.best_estimator_"
      ],
      "metadata": {
        "id": "kIbNCBxESPNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The topics and topic terms can be visualised to help assess how interpretable the topic model is"
      ],
      "metadata": {
        "id": "btVe-XzpgWe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import plotly.express as px"
      ],
      "metadata": {
        "id": "UzKN5cM0gnCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to get the subjectivity\n",
        "def subjectivity(text):\n",
        "    return TextBlob(text).sentiment.subjectivity"
      ],
      "metadata": {
        "id": "3jfkQ0shgqKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to get the polarity\n",
        "def polarity(text):\n",
        "    return TextBlob(text).sentiment.polarity"
      ],
      "metadata": {
        "id": "hmZ1hg9ggsyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying subjectivity and the polarity function to the respective columns\n",
        "review_df['Subjectivity'] = review_df['Review'].apply(subjectivity)\n",
        "review_df['Polarity'] = review_df['Review'].apply(polarity)"
      ],
      "metadata": {
        "id": "A_GvC4whgvUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for created columns\n",
        "review_df['Polarity']"
      ],
      "metadata": {
        "id": "p7a0SoNagx5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for created columns\n",
        "review_df['Subjectivity']"
      ],
      "metadata": {
        "id": "OtjayVh4g1VU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to compute the negative, neutral and positive analysis\n",
        "def getAnalysis(score):\n",
        "    if score <0:\n",
        "        return 'Negative'\n",
        "    elif score == 0:\n",
        "        return 'Neutral'\n",
        "    else:\n",
        "        return 'Positive'"
      ],
      "metadata": {
        "id": "7AeZeCetg4BL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the score is less than 0, the function returns the string 'Negative'. If the score is equal to 0, the function returns the string 'Neutral'. If the score is greater than 0, the function returns the string 'Positive'."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply get analysis function to separate the sentiments from the column\n",
        "review_df['Analysis'] = review_df['Polarity'].apply(getAnalysis)"
      ],
      "metadata": {
        "id": "H3_SnMoVg_9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the polarity and subjectivity\n",
        "fig = px.scatter(review_df,\n",
        "                 x='Polarity',\n",
        "                 y='Subjectivity',\n",
        "                 color = 'Analysis',\n",
        "                 size='Subjectivity')"
      ],
      "metadata": {
        "id": "JAmA69u0hDdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a vertical line at x=0 for Netural Reviews\n",
        "fig.update_layout(title='Sentiment Analysis',\n",
        "                  shapes=[dict(type= 'line',\n",
        "                               yref= 'paper', y0= 0, y1= 1,\n",
        "                               xref= 'x', x0= 0, x1= 0)])\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "b8ZqQSm9hGOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The resulting plot can provide several insights into the sentiment analysis results. Firstly, the histogram bars on the left side of the plot (negative polarity) indicate that a significant number of reviews expressed negative sentiments. Similarly, the histogram bars on the right side of the plot (positive polarity) indicate that a significant number of reviews expressed positive sentiments.\n",
        "\n",
        "Overall, this plot can provide a quick and easy way to visualize the sentiment polarity distribution of the reviews, which can help in understanding the overall sentiment of the customers towards the restaurants."
      ],
      "metadata": {
        "id": "W-xT61KAhKfp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning);"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting the cuisines to lower case\n",
        "\n",
        "meta_df_main['Cuisines'] = meta_df_main['Cuisines'].apply(lambda x : x.lower())"
      ],
      "metadata": {
        "id": "N0ThRAJZhePV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separating the Name, cost and cuisines column.\n",
        "cuisine_df = meta_df_main.loc[:,['Name','Cost','Cuisines']]"
      ],
      "metadata": {
        "id": "CcVuK7nchlDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Overview of separated variables.\n",
        "cuisine_df.head()"
      ],
      "metadata": {
        "id": "uFGs0rfVhoWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing spces from cuisine column.\n",
        "cuisine_df['Cuisines'] = cuisine_df['Cuisines'].str.replace(' ','')\n",
        "\n",
        "# Spliting the Words in cuisine.\n",
        "cuisine_df['Cuisines'] = cuisine_df['Cuisines'].str.split(',')"
      ],
      "metadata": {
        "id": "SsmcmBp2hrUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Overview on text cleaning.\n",
        "cuisine_df.head()"
      ],
      "metadata": {
        "id": "tvSlSFbchuFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# converting a list of labels for each sample into a binary indicator matrix\n",
        "mlb = MultiLabelBinarizer(sparse_output=True)"
      ],
      "metadata": {
        "id": "ltNv1pAAhxhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting the Cuisines column in the cuisine_df DataFrame into a binary indicator matrix.\n",
        "cuisine_df = cuisine_df.join(pd.DataFrame.sparse.from_spmatrix(mlb.fit_transform(cuisine_df.pop('Cuisines')),\n",
        "                                                               index=cuisine_df.index, columns=mlb.classes_))"
      ],
      "metadata": {
        "id": "0VE98rSHh0wI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Overview\n",
        "cuisine_df.head()"
      ],
      "metadata": {
        "id": "h9Prc9owh4Ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the unique for rating.\n",
        "review_df['Rating'].unique()"
      ],
      "metadata": {
        "id": "8QakBPunh7sH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove nan rating in Rating column.\n",
        "review_df.dropna(subset=['Rating'],inplace=True)"
      ],
      "metadata": {
        "id": "h49BbSa7h-5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change data type of rating column to float.\n",
        "review_df['Rating']= review_df['Rating'].astype('float')"
      ],
      "metadata": {
        "id": "1ZHG7rm3iCx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping the null Values from review column.\n",
        "review_df.dropna(subset =['Review'], inplace=True)"
      ],
      "metadata": {
        "id": "BuPBe1fmiHPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouping the restaurant on the basis of average rating.\n",
        "ratings_df = review_df.groupby('Restaurant')['Rating'].mean().reset_index()"
      ],
      "metadata": {
        "id": "1Ga-UrrsiJvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top highly rated 15 restaurants.\n",
        "ratings_df .sort_values(by='Rating',ascending = False).head(15)"
      ],
      "metadata": {
        "id": "QGvB2K6IiJ5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Combining the information on restaurant cuisine and ratings into a single DataFrame.\n",
        "df_cluster = cuisine_df.merge(ratings_df, left_on='Name',right_on='Restaurant')"
      ],
      "metadata": {
        "id": "cRktHmBoiQT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Overview\n",
        "df_cluster.head()"
      ],
      "metadata": {
        "id": "V58SWl9NiTC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing name and order of columns\n",
        "df_cluster = df_cluster[['Name', 'Cost','Rating', 'american', 'andhra', 'arabian', 'asian', 'bbq',\n",
        "       'bakery', 'beverages', 'biryani', 'burger', 'cafe', 'chinese',\n",
        "       'continental', 'desserts', 'european', 'fastfood', 'fingerfood', 'goan',\n",
        "       'healthyfood', 'hyderabadi', 'icecream', 'indonesian', 'italian',\n",
        "       'japanese', 'juices', 'kebab', 'lebanese', 'malaysian', 'mediterranean',\n",
        "       'mexican', 'mithai', 'modernindian', 'momos', 'mughlai', 'northeastern',\n",
        "       'northindian', 'pizza', 'salad', 'seafood', 'southindian', 'spanish',\n",
        "       'streetfood', 'sushi', 'thai', 'wraps']]"
      ],
      "metadata": {
        "id": "fEcCzmhEiXz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the data type and null counts for newly created variables.\n",
        "df_cluster.info()"
      ],
      "metadata": {
        "id": "qP4OWdCHiaNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing commas from the cost variables.\n",
        "df_cluster['Cost']= df_cluster['Cost'].str.replace(',','')"
      ],
      "metadata": {
        "id": "NacDAMqFic95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing the data type of the cost column.\n",
        "df_cluster['Cost']= df_cluster['Cost'].astype('float')"
      ],
      "metadata": {
        "id": "QWJmAppSievs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualising relationship between the cost of a meal and the rating of a restaurant\n",
        "sns.lmplot(y='Rating',x='Cost',data=df_cluster,line_kws={'color' :'red'},height=6.27, aspect=11.7/8.27)"
      ],
      "metadata": {
        "id": "vXZjpPnJii9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The resulting plot shows the relationship between the cost of a meal and the rating of a restaurant, with the regression line indicating the general trend in the data. This can help identify any patterns or correlations between cost and rating."
      ],
      "metadata": {
        "id": "n59mIfuZim_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-means Clustering"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from yellowbrick.cluster import KElbowVisualizer"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of inertia scores for different numbers of clusters\n",
        "scores = [KMeans(n_clusters=i+2, random_state=11).fit(df_cluster.drop('Name',axis=1)).inertia_\n",
        "          for i in range(8)]\n",
        "\n",
        "# Create a line plot of inertia scores versus number of clusters\n",
        "plt.figure(figsize=(7,7))\n",
        "sns.lineplot(x=np.arange(2, 10), y=scores)\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('Inertia')\n",
        "plt.title('Inertia of k-Means versus number of clusters')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UiCSn6R6i6X4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The plot can help to identify the optimal number of clusters based on the elbow point of the curve, where the rate of decrease in inertia score slows down significantly."
      ],
      "metadata": {
        "id": "bmgZzWsojhxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing a K-Means clustering model with number of clusters and random state.\n",
        "model = KMeans(random_state=11, n_clusters=5)\n",
        "model.fit(df_cluster.drop('Name',axis=1))"
      ],
      "metadata": {
        "id": "fKmvbNmKi_7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict the cluster label of a new data point based on a trained clustering model.\n",
        "cluster_lbl = model.predict(df_cluster.drop('Name',axis=1))"
      ],
      "metadata": {
        "id": "RRiQlGGDjHi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cluster['labels'] = cluster_lbl"
      ],
      "metadata": {
        "id": "2jHBIaiVjJ7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the data frame for each cluster.\n",
        "cluster_0 = df_cluster[df_cluster['labels'] == 0].reset_index()\n",
        "cluster_1 = df_cluster[df_cluster['labels'] == 1].reset_index()\n",
        "cluster_2 = df_cluster[df_cluster['labels'] == 2].reset_index()\n",
        "cluster_3 = df_cluster[df_cluster['labels'] == 3].reset_index()\n",
        "cluster_4 = df_cluster[df_cluster['labels'] == 4].reset_index()"
      ],
      "metadata": {
        "id": "PXT_ChhPjMqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_cluster=[cluster_0,cluster_1,cluster_2,cluster_3,cluster_4]"
      ],
      "metadata": {
        "id": "JAlZFkRUjO_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a scatter plot of the clusters with annotations for top cuisines\n",
        "plt.figure(figsize=(15,7))\n",
        "sns.scatterplot(x='Cost', y='Rating', hue='labels', data=df_cluster)\n",
        "\n",
        "# Add annotations for top cuisines in each cluster\n",
        "for i, df in enumerate(list_of_cluster):\n",
        "    top_cuisines = df.drop(['index', 'Name', 'Cost', 'Rating', 'labels'], axis=1).sum().sort_values(ascending=False)[:3]\n",
        "    top_cuisines_str = '\\n'.join([f'{cuisine}: {count}' for cuisine, count in top_cuisines.items()])\n",
        "    plt.annotate(f'Top cuisines in cluster {i}\\n{top_cuisines_str}',\n",
        "                 xy=(df['Cost'].mean(), df['Rating'].mean()),\n",
        "                 ha='center', va='center', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "\n",
        "plt.xlabel('Cost')\n",
        "plt.ylabel('Rating')\n",
        "plt.title('Clustering of Restaurants')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "U5G91DoZjSQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each cluster, the top three cuisines are identified and annotated on the plot. The annotation includes the name of the cluster, its centroid location (mean cost and mean rating), and the top three cuisines and their counts within the cluster. This plot can be used to visually identify how the restaurants are grouped and the dominant features of each cluster."
      ],
      "metadata": {
        "id": "pklJTesrjZSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Top cuisines in each cluster\n",
        "for i,df in enumerate(list_of_cluster):\n",
        "  print(f'Top cuisines in cluster {i}\\n', df.drop(['index','Name','Cost','Rating','labels'],axis=1).sum().sort_values(ascending=False)[:3],'\\n')"
      ],
      "metadata": {
        "id": "6b5k-vBAjoXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The project was successful in achieving the goals of clustering and sentiment analysis. The clustering part provided insights into the grouping of restaurants based on their features, which can help in decision making for users and businesses. The sentiment analysis part provided insights into the sentiments expressed by the users in their reviews, which can help businesses in improving their services and user experience.\n",
        "\n",
        "There are several potential areas for future work, such as implementing more advanced clustering algorithms and sentiment analysis techniques, incorporating more features such as images and menus of the restaurants, and exploring the relationships between the clustering and sentiment analysis results."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}